{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pysal.lib import weights\n",
    "from pysal.explore import esda\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import contextily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the data\n",
    "path = r'YOUR FILE PATH'\n",
    "\n",
    "# REMINDER - The listings data must be downloaded from Inside Airbnb\n",
    "listings = pd.read_csv(path + r'NY Airbnb June 2020\\listings.csv.gz', compression='gzip', low_memory=False)\n",
    "\n",
    "# Converting it to a GeoPandas DataFrame\n",
    "listings_gpdf = gpd.GeoDataFrame(\n",
    "    listings,\n",
    "    geometry=gpd.points_from_xy(listings['longitude'],\n",
    "                                   listings['latitude'],\n",
    "                                   crs=\"EPSG:4326\")\n",
    ")\n",
    "\n",
    "# Focusing on attractions in Manhattan, so we need to create a mask to filter locations \n",
    "# in the Manhattan borough\n",
    "boroughs = gpd.read_file(path + r\"NYC Boroughs\\nybb_22a\\nybb.shp\")\n",
    "manhattan = boroughs[boroughs['BoroName']=='Manhattan']\n",
    "manhattan = manhattan.to_crs('EPSG:4326')\n",
    "\n",
    "listings_mask = listings_gpdf.within(manhattan.loc[3, 'geometry'])\n",
    "\n",
    "listings_manhattan = listings_gpdf.loc[listings_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(listings_manhattan.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting the data to a handful of variables that could be indicative of nightly airbnb price\n",
    "voi = ['id' # Unique identifier for the listing\n",
    "       ,'room_type' # Type of room\n",
    "       ,'accommodates' # The maximum capacity of the listing \n",
    "       ,'bedrooms' # The number of bedrooms\n",
    "       ,'beds' # The number of beds\n",
    "       ,'review_scores_rating' # The rating\n",
    "       ,'price' # The nightly rental rate, dependent variable (Y)\n",
    "      ]\n",
    "\n",
    "listings_manhattan_subset = listings_manhattan[voi]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Exploratory Data Analysis & Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_manhattan_subset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in listings_manhattan[['room_type']]:\n",
    "  print(listings_manhattan_subset[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical variables\n",
    "\n",
    "# Room Type, All 0s = hotel room\n",
    "listings_manhattan_subset['rt_entire_home_apartment'] = np.where(listings_manhattan_subset[\"room_type\"]=='Entire home/apt', 1, 0)\n",
    "listings_manhattan_subset['rt_private_room'] = np.where(listings_manhattan_subset[\"room_type\"]=='Private room', 1, 0)\n",
    "listings_manhattan_subset['rt_shared_room'] = np.where(listings_manhattan_subset[\"room_type\"]=='Shared room', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_manhattan_subset['price'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning up the price column\n",
    "listings_manhattan_subset['price'] = listings_manhattan_subset['price'].str.replace('$', '')\n",
    "listings_manhattan_subset['price'] = listings_manhattan_subset['price'].str.replace(',', '')\n",
    "listings_manhattan_subset['price'] = listings_manhattan_subset['price'].astype(float)\n",
    "\n",
    "# Logging the price variable\n",
    "listings_manhattan_subset['log_price'] = np.log(listings_manhattan_subset['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missingness\n",
    "print('Total Records:', len(listings_manhattan_subset))\n",
    "listings_manhattan_subset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_manhattan_subset = listings_manhattan_subset[listings_manhattan_subset['bedrooms'].notna()]\n",
    "listings_manhattan_subset = listings_manhattan_subset[listings_manhattan_subset['review_scores_rating'].notna()]\n",
    "listings_manhattan_subset = listings_manhattan_subset[listings_manhattan_subset['beds'].notna()]\n",
    "listings_manhattan_subset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. OLS Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysal.model import spreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a list of explanatory variables\n",
    "m_vars = ['accommodates', 'bedrooms','beds','review_scores_rating',\n",
    "          'rt_entire_home_apartment','rt_private_room','rt_shared_room'\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_m = spreg.OLS(\n",
    "    listings_manhattan_subset[[\"log_price\"]].values # the dependent variable (Y)\n",
    "    ,listings_manhattan_subset[m_vars].values # the independent variables(Xs)\n",
    "    ,name_y = 'price',\n",
    "    name_x = m_vars\n",
    ")\n",
    "\n",
    "print(ols_m.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Exploring unmodeled relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a column to store the model residuals\n",
    "listings_manhattan_subset[\"ols_m_r\"] = ols_m.u\n",
    "\n",
    "# Bringing back in the neighborhood variable\n",
    "listings_manhattan_subset = listings_manhattan_subset.merge(listings_manhattan[['id','neighbourhood_cleansed']], how='left',on='id')\n",
    "\n",
    "# Get average value of the residual by neighborhood\n",
    "mean = (\n",
    "    listings_manhattan_subset.groupby(\"neighbourhood_cleansed\")\n",
    "    .ols_m_r.mean()\n",
    "    .to_frame(\"neighborhood_residual\")\n",
    ")\n",
    "\n",
    "# Creating a dataframe to store the residuals by neighborhood\n",
    "residuals_neighborhood = listings_manhattan_subset.merge(\n",
    "        mean, how=\"left\", left_on=\"neighbourhood_cleansed\", right_index=True\n",
    "    ).sort_values(\"neighborhood_residual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Plotting the distribution of the residuals in a violin plot\n",
    "fig = px.violin(residuals_neighborhood, x=\"neighbourhood_cleansed\", y=\"ols_m_r\", color=\"neighbourhood_cleansed\", box=True)\n",
    "# Updating the x and y axis labels\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Neighborhood\", yaxis_title=\"Residuals\"\n",
    ")\n",
    "HTML(fig.to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Producing a map of the average residual by neighborhood\n",
    "import requests\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape\n",
    "\n",
    "# Reading in the NYC Neighborhoods shapefile from data file\n",
    "import os\n",
    "\n",
    "nyc_n = gpd.read_file(os.path.join(path,r\"NYC Neighborhoods\\NYC_Neighborhoods.geojson\"), driver='GeoJSON')\n",
    "\n",
    "# Merging\n",
    "nyc_n_r = nyc_n.merge(mean, left_on='neighborhood', right_on=\"neighbourhood_cleansed\")\n",
    "\n",
    "f, ax = plt.subplots(1, figsize=(15, 25))\n",
    "   \n",
    "# Plot choropleth of local statistics\n",
    "nyc_n_r.plot(\n",
    "    column='neighborhood_residual', \n",
    "    cmap='vlag', \n",
    "    scheme='quantiles',\n",
    "    k=4, \n",
    "    edgecolor='white', \n",
    "    linewidth=0.1, \n",
    "    alpha=0.75,\n",
    "    legend=True,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# Add basemap\n",
    "contextily.add_basemap(\n",
    "    ax,\n",
    "    crs=nyc_n.crs,\n",
    "    source=contextily.providers.Stamen.Watercolor,\n",
    ")\n",
    "\n",
    "for idx, row in nyc_n_r.iterrows():\n",
    "    txt=row['neighborhood']\n",
    "    n_txt = '\\n'.join(textwrap.wrap(txt, width=11, replace_whitespace=True))\n",
    "    #print(n_txt)                  \n",
    "    plt.annotate(text=n_txt, xy=tuple([row.geometry.centroid.x, row.geometry.centroid.y]),\n",
    "                 horizontalalignment='center',fontsize=14, rotation=50, wrap=True)\n",
    "\n",
    "    \n",
    "# Remove axis\n",
    "ax.set_axis_off()\n",
    "\n",
    "# Display\n",
    "plt.show()\n",
    "#f.savefig(r\"G:\\My Drive\\Geospatial Data Science with Python\\Neighborhood Residuals.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bringing in the geometry attribute\n",
    "residuals_neighborhood = residuals_neighborhood.merge(listings_manhattan[['id','geometry']], how='left',on='id')\n",
    "\n",
    "# Building the spatial weights matrix\n",
    "knn = weights.KNN.from_dataframe(residuals_neighborhood, k=5)\n",
    "\n",
    "# Constructing the spatial lag\n",
    "lag_residual = weights.spatial_lag.lag_spatial(knn, ols_m.u)\n",
    "\n",
    "# Plotting the results\n",
    "fig = px.scatter(x=ols_m.u.flatten(), y=lag_residual.flatten(), trendline=\"ols\",\n",
    "                width=800, height=800)\n",
    "\n",
    "# Updating the x and y axis labels\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Airbnb Residuals\", yaxis_title=\"Spatially Lagged Residuals\"\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. OLS Regression Analysis w/ Spatial Atributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Spatial Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in data on popular NYC Attractions\n",
    "nyc_attr = pd.read_csv(path + 'NYC Attractions\\\\NYC Attractions.csv')\n",
    "\n",
    "# Convert PDF to GPDF\n",
    "nyc_attr_gpdf =  gpd.GeoDataFrame(\n",
    "    nyc_attr,\n",
    "    geometry=gpd.points_from_xy(nyc_attr['Longitude'],\n",
    "                                   nyc_attr['Latitude'],\n",
    "                                   crs=\"EPSG:4326\")\n",
    ")\n",
    "\n",
    "# Calculate the distance to each attraction per airbnb\n",
    "attractions = nyc_attr_gpdf.Attraction.unique()\n",
    "\n",
    "# Converting to a projected coordinate system\n",
    "nyc_attr_gpdf_p = nyc_attr_gpdf.to_crs('EPSG:2263')\n",
    "listings_manhattan_p = listings_manhattan.to_crs('EPSG:2263')\n",
    "\n",
    "# Applying a lambda function that calls geopandas distance function to calcuate the distance between each airbnb and each attraction\n",
    "distances = listings_manhattan_p.geometry.apply(lambda g: nyc_attr_gpdf_p.distance(g))\n",
    "\n",
    "# Renaming the columns based on the attraction for which the distance is calculated\n",
    "distances.columns = attractions\n",
    "\n",
    "# Convert from 'US survey foot' to miles\n",
    "distances = distances.apply(lambda x: x/5280, axis=1)\n",
    "\n",
    "# Check to see which locations are less than 1 to 6 miles\n",
    "distances_1mi = distances.apply(lambda x: x <=1, axis=1).sum(axis=1)\n",
    "distances_2mi = distances.apply(lambda x: x <=2, axis=1).sum(axis=1)\n",
    "distances_3mi = distances.apply(lambda x: x <=3, axis=1).sum(axis=1)\n",
    "distances_4mi = distances.apply(lambda x: x <=4, axis=1).sum(axis=1)\n",
    "distances_5mi = distances.apply(lambda x: x <=5, axis=1).sum(axis=1)\n",
    "distances_6mi = distances.apply(lambda x: x <=6, axis=1).sum(axis=1)\n",
    "\n",
    "# Creating a dataframe combining all the distance bands\n",
    "distance_df = pd.concat([distances_1mi,distances_2mi,distances_3mi,distances_4mi,distances_5mi,distances_6mi], axis=1)\n",
    "distance_df.columns = ['Attr_1mi','Attr_2mi','Attr_3mi','Attr_4mi','Attr_5mi','Attr_6mi']\n",
    "\n",
    "# Joining back to the listings geopandas df\n",
    "listings_manhattan = listings_manhattan.merge(distances, left_index=True, right_index=True)\n",
    "listings_manhattan = listings_manhattan.merge(distance_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Modeling with Proximity Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geographic Features\n",
    "g_vars = ['Central Park', 'Central Park Zoo', 'Empire State Building', 'Statue of Liberty', \n",
    "          'Rockeffeller Center', 'Chrysler Building', 'Times Square', 'MoMa', 'Charging Bull']\n",
    "\n",
    "# Bring the geographic features into our subset\n",
    "listings_manhattan_subset = listings_manhattan_subset.merge(listings_manhattan[['id','Central Park', 'Central Park Zoo', 'Empire State Building', 'Statue of Liberty', \n",
    "          'Rockeffeller Center', 'Chrysler Building', 'Times Square', 'MoMa', 'Charging Bull']], how='left',on='id')\n",
    "\n",
    "# Adding geographic features to model variables used previously\n",
    "g_m_vars = m_vars + g_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_m_g = spreg.OLS(\n",
    "    listings_manhattan_subset[[\"log_price\"]].values,\n",
    "    listings_manhattan_subset[g_m_vars].values,\n",
    "    name_y = 'price',\n",
    "    name_x = g_m_vars\n",
    ")\n",
    "\n",
    "print(ols_m_g.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_diagnostics = pd.DataFrame(\n",
    "    [[ols_m.r2, ols_m.ar2], [ols_m_g.r2, ols_m_g.ar2]],\n",
    "    index=[\"OLS_M\", \"OLS_M_G\"],\n",
    "    columns=[\"R2\", \"Adj. R2\"],\n",
    ")\n",
    "\n",
    "model_diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing the spatial lag\n",
    "lag_residual_2 = weights.spatial_lag.lag_spatial(knn, ols_m_g.u)\n",
    "\n",
    "# Plotting the results\n",
    "fig = px.scatter(x=ols_m_g.u.flatten(), y=lag_residual_2.flatten(), trendline=\"ols\",\n",
    "                width=800, height=800, title=\"Residual Plot for OLS Model with Geospatial Features\")\n",
    "\n",
    "# Updating the x and y axis labels\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Airbnb Residuals\", yaxis_title=\"Spatially Lagged Residuals\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Spatial Fixed Effects Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bringing back in the neighbourhood_cleansed variable\n",
    "listings_manhattan_subset = listings_manhattan_subset.merge(listings_manhattan[['id','neighbourhood_cleansed']], how='left',on='id')\n",
    "\n",
    "# spatial fixed effect model implementation\n",
    "sfe_m = spreg.OLS_Regimes(\n",
    "    #The dependent variable (Y) - Log Price (log_price)\n",
    "    listings_manhattan_subset[[\"log_price\"]].values,\n",
    "    \n",
    "    # The independent variables (Xs)\n",
    "    listings_manhattan_subset[g_m_vars].values,\n",
    "    \n",
    "    # Variable which specifies which neighborhood each airbnb falls within\n",
    "    listings_manhattan_subset[\"neighbourhood_cleansed\"].tolist(),\n",
    "    \n",
    "    # Vary constant by each cross-section/group\n",
    "    constant_regi=\"many\",\n",
    "    \n",
    "    # Here we tell the model that the variables are kept constant by group\n",
    "    cols2regi=[False] * len(g_m_vars),\n",
    "    \n",
    "    # Here we tell the model to estimate a single sigma coefficient\n",
    "    regime_err_sep=False,\n",
    "    \n",
    "    # Dependent variable name\n",
    "    name_y=\"log_price\",\n",
    "    \n",
    "    # Independent variables names\n",
    "    name_x=g_m_vars,\n",
    ")\n",
    "# printing the model summary\n",
    "print(sfe_m.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Chow Statistic \n",
    "sfe_m.chow.joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing the spatial lag\n",
    "lag_residual_3 = weights.spatial_lag.lag_spatial(knn, sfe_m.u)\n",
    "\n",
    "# Plotting the results\n",
    "fig = px.scatter(x=sfe_m.u.flatten(), y=lag_residual_3.flatten(), trendline=\"ols\",\n",
    "                width=800, height=800, title=\"Residual Plot for SFE OLS Model\")\n",
    "\n",
    "# Updating the x and y axis labels\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Airbnb Residuals\", yaxis_title=\"Spatially Lagged Residuals\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Geographically Weighted Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mgwr.gwr import GWR\n",
    "from mgwr.sel_bw import Sel_BW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical variables\n",
    "\n",
    "# Room Type, All 0s = hotel room\n",
    "listings_manhattan['rt_entire_home_apartment'] = np.where(listings_manhattan[\"room_type\"]=='Entire home/apt', 1, 0)\n",
    "listings_manhattan['rt_private_room'] = np.where(listings_manhattan[\"room_type\"]=='Private room', 1, 0)\n",
    "listings_manhattan['rt_shared_room'] = np.where(listings_manhattan[\"room_type\"]=='Shared room', 1, 0)\n",
    "\n",
    "# Cleaning up the price column\n",
    "listings_manhattan['price'] = listings_manhattan['price'].str.replace('$', '')\n",
    "listings_manhattan['price'] = listings_manhattan['price'].str.replace(',', '')\n",
    "listings_manhattan['price'] = listings_manhattan['price'].astype(float)\n",
    "\n",
    "# Logging the price variable\n",
    "listings_manhattan['log_price'] = np.log(listings_manhattan['price'])\n",
    "\n",
    "listings_manhattan = listings_manhattan[listings_manhattan['bedrooms'].notna()]\n",
    "listings_manhattan = listings_manhattan[listings_manhattan['review_scores_rating'].notna()]\n",
    "listings_manhattan = listings_manhattan[listings_manhattan['beds'].notna()]\n",
    "listings_manhattan.isna().sum()\n",
    "\n",
    "listings_manhattan = listings_manhattan[listings_manhattan['bedrooms'].notna()]\n",
    "listings_manhattan = listings_manhattan[listings_manhattan['review_scores_rating'].notna()]\n",
    "listings_manhattan = listings_manhattan[listings_manhattan['beds'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the explanatory variables\n",
    "exp_vars = listings_manhattan[['accommodates', 'bedrooms','beds','review_scores_rating']].values\n",
    "\n",
    "# Setting the dependent variable: log_price\n",
    "y = (listings_manhattan['log_price'].values).reshape((-1,1))\n",
    "\n",
    "# Defining the coordinates of the observations\n",
    "coords = list(zip(listings_manhattan.geometry.x,listings_manhattan.geometry.y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the optimal bandwidth for the explanatory variables\n",
    "gwr_selector = Sel_BW(coords, y, exp_vars, spherical=True)\n",
    "gwr_bw = gwr_selector.search(bw_min=2)\n",
    "\n",
    "# Displaying the optimal bandwidth\n",
    "gwr_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the GWR model to your data\n",
    "gwr_results = GWR(coords, listings_manhattan[[\"log_price\"]].values, \n",
    "                     exp_vars, gwr_bw).fit()\n",
    "\n",
    "# Print the results of the GWR model\n",
    "print(gwr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwr_results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = gwr_results.resid_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing the spatial lag\n",
    "lag_residual_4 = weights.spatial_lag.lag_spatial(knn, residuals)\n",
    "\n",
    "# Plotting the results\n",
    "fig = px.scatter(x=residuals.flatten(), y=lag_residual_4.flatten(), trendline=\"ols\",\n",
    "                width=800, height=800, title=\"Residual Plot for GWR Model\")\n",
    "\n",
    "# Updating the x and y axis labels\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Airbnb Residuals\", yaxis_title=\"MGWR Residuals\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Multi-scale Geographically Weighted Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mgwr.gwr import MGWR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_manhattan_sample = listings_manhattan.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_vars = listings_manhattan_sample[['accommodates', 'bedrooms','review_scores_rating']].values\n",
    "y = (listings_manhattan_sample['price'].values).reshape((-1,1))\n",
    "coords = list(zip(listings_manhattan_sample.geometry.x,listings_manhattan_sample.geometry.y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing\n",
    "exp_vars = (exp_vars - exp_vars.mean(axis=0)) / exp_vars.std(axis=0)\n",
    "y = (y - y.mean(axis=0)) / y.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = Sel_BW(coords, y, exp_vars, multi=True, spherical=True)\n",
    "selector.search(multi_bw_min=[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the GWR model to your data\n",
    "mgwr_results = MGWR(coords, y, exp_vars, selector, sigma2_v1=True).fit()\n",
    "\n",
    "# Print the results of the GWR model\n",
    "print(mgwr_results)\n",
    "\n",
    "mgwr_results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MGWR with Binary Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mgwr.gwr import GWR, MGWR\n",
    "from mgwr.sel_bw import Sel_BW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical variables\n",
    "\n",
    "# Room Type, All 0s = hotel room\n",
    "listings_manhattan['rt_entire_home_apartment'] = np.where(listings_manhattan[\"room_type\"]=='Entire home/apt', 1, 0)\n",
    "listings_manhattan['rt_private_room'] = np.where(listings_manhattan[\"room_type\"]=='Private room', 1, 0)\n",
    "listings_manhattan['rt_shared_room'] = np.where(listings_manhattan[\"room_type\"]=='Shared room', 1, 0)\n",
    "\n",
    "# Cleaning up the price column\n",
    "listings_manhattan['price'] = listings_manhattan['price'].str.replace('$', '')\n",
    "listings_manhattan['price'] = listings_manhattan['price'].str.replace(',', '')\n",
    "listings_manhattan['price'] = listings_manhattan['price'].astype(float)\n",
    "\n",
    "# Logging the price variable\n",
    "listings_manhattan['log_price'] = np.log(listings_manhattan['price'])\n",
    "\n",
    "listings_manhattan = listings_manhattan[listings_manhattan['bedrooms'].notna()]\n",
    "listings_manhattan = listings_manhattan[listings_manhattan['review_scores_rating'].notna()]\n",
    "listings_manhattan = listings_manhattan[listings_manhattan['beds'].notna()]\n",
    "listings_manhattan.isna().sum()\n",
    "\n",
    "listings_manhattan = listings_manhattan[listings_manhattan['bedrooms'].notna()]\n",
    "listings_manhattan = listings_manhattan[listings_manhattan['review_scores_rating'].notna()]\n",
    "listings_manhattan = listings_manhattan[listings_manhattan['beds'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_manhattan_sample = listings_manhattan.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_manhattan_sample[['accommodates', 'bedrooms','review_scores_rating',\n",
    "          'Central Park', 'Central Park Zoo', 'Empire State Building', 'Statue of Liberty', \n",
    "          'Rockeffeller Center', 'Chrysler Building', 'Times Square', 'MoMa', 'Charging Bull']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_vars = listings_manhattan_sample[['accommodates', 'bedrooms','review_scores_rating',\n",
    "          'Central Park', 'Central Park Zoo', 'Empire State Building', 'Statue of Liberty', \n",
    "          'Rockeffeller Center', 'Chrysler Building', 'Times Square', 'MoMa', 'Charging Bull']].values\n",
    "y = (listings_manhattan_sample['price'].values).reshape((-1,1))\n",
    "coords = list(zip(listings_manhattan_sample.geometry.x,listings_manhattan_sample.geometry.y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing\n",
    "exp_vars = (exp_vars - exp_vars.mean(axis=0)) / exp_vars.std(axis=0)\n",
    "y = (y - y.mean(axis=0)) / y.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    selector = Sel_BW(coords, y, exp_vars, multi=True, spherical=True)\n",
    "    selector.search(multi_bw_min=[15])\n",
    "    result += 1\n",
    "except:\n",
    "    print('Doesnt work for ' + str(i))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the GWR model to your data\n",
    "mgwr_results = MGWR(coords, y, exp_vars, selector, fixed=False, sigma2_v1=True).fit()\n",
    "\n",
    "# Print the results of the GWR model\n",
    "print(mgwr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgwr_results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
