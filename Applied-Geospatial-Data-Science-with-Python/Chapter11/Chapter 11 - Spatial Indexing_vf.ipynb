{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39b99048",
   "metadata": {},
   "source": [
    "# 1.0 Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753536fb",
   "metadata": {},
   "source": [
    "## 1.1 Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b23c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import time\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon\n",
    "import osmnx as ox\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc95ba2c",
   "metadata": {},
   "source": [
    "## 1.2 Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9d21f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the file path\n",
    "path = r'YOUR FILE PATH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdf8909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the data as a Pandas DataFrame\n",
    "#REMINDER - The listings data must be downloaded from Inside Airbnb\n",
    "listings = pd.read_csv(path + r'NY Airbnb June 2020\\listings.csv.gz', compression='gzip', low_memory=False)\n",
    "\n",
    "# Converting it to a GeoPandas DataFrame\n",
    "listings_gpdf = gpd.GeoDataFrame(\n",
    "    listings,\n",
    "    geometry=gpd.points_from_xy(listings['longitude'],\n",
    "                                   listings['latitude'],\n",
    "                                   crs=\"EPSG:4326\")\n",
    ")\n",
    "\n",
    "# Printing the shape of the DataFrame\n",
    "listings_gpdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0b67b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focusing on attractions in Manhattan, so we need to create a mask to filter locations \n",
    "# in the Manhattan borough\n",
    "boroughs = gpd.read_file(path + r\"NYC Boroughs\\nybb_22a\\nybb.shp\")\n",
    "boroughs = boroughs.to_crs('EPSG:4326')\n",
    "manhattan = boroughs[boroughs['BoroName']=='Manhattan']\n",
    "\n",
    "# get the start time\n",
    "st = time.time()\n",
    "\n",
    "listings_mask = listings_gpdf.within(manhattan.loc[3, 'geometry'])\n",
    "\n",
    "listings_manhattan = listings_gpdf.loc[listings_mask]\n",
    "\n",
    "# get the end time\n",
    "et = time.time()\n",
    "\n",
    "# get the execution time\n",
    "elapsed_time = et - st\n",
    "print('Execution time:', elapsed_time, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf9734a",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_manhattan.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d432421",
   "metadata": {},
   "source": [
    "# 2.0 Spatial Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7019f376",
   "metadata": {},
   "source": [
    "## 2.1 R-Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082701dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the R-tree spatial index\n",
    "sindex = listings_gpdf.sindex\n",
    "\n",
    "# get the start time\n",
    "st = time.time()\n",
    "\n",
    "# Getting the indexes of the possible matches from the R-tree\n",
    "idex_possible_matches = list(sindex.intersection(geometry.bounds))\n",
    "\n",
    "# subsetting the dataframe to be only possible matches\n",
    "possible_matches_df = listings_gpdf.iloc[idex_possible_matches]\n",
    "\n",
    "# Performing an intersection to get the precise matches\n",
    "precise_matches_df = possible_matches_df[possible_matches_df.intersects(geometry)]\n",
    "\n",
    "# get the end time\n",
    "et = time.time()\n",
    "\n",
    "# get the execution time\n",
    "elapsed_time = et - st\n",
    "print('Execution time:', elapsed_time, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86caf5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "precise_matches.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0d637e",
   "metadata": {},
   "source": [
    "### 2.1.1 R-Tree with Subdivided Polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4f6ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idenitifying units of measurement\n",
    "listings_gpdf.crs.axis_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c8be1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the subdivided polygons\n",
    "subdivided_polygon = ox.utils_geo._quadrat_cut_geometry(geometry, quadrat_width=1) # quadrant_width is in the CRS measurement units (4326:degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0ca28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the start time\n",
    "st = time.time()\n",
    "\n",
    "points_in_geometry = pd.DataFrame()\n",
    "for geom in subdivided_polygon:\n",
    "    # add in a slight buffer to account for points falling on the lines of the subdivided polygons\n",
    "    geom = geom.buffer(1e-14).buffer(0)\n",
    "\n",
    "    # Getting the indexes of the possible matches from the R-tree\n",
    "    idex_possible_matches = list(sindex.intersection(geom.bounds))\n",
    "    possible_matches_df = listings_gpdf.iloc[idex_possible_matches]\n",
    "    \n",
    "    # Performing an intersection to get the precise matches\n",
    "    precise_matches_df = possible_matches_df[possible_matches_df.intersects(geom)]\n",
    "    points_in_geometry = points_in_geometry.append(precise_matches_df)\n",
    "\n",
    "# get the end time\n",
    "et = time.time()\n",
    "\n",
    "# get the execution time\n",
    "elapsed_time = et - st\n",
    "print('Execution time:', elapsed_time, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d1a8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_in_geometry.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afeb1e4d",
   "metadata": {},
   "source": [
    "## 2.2 H3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948268af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference Materials\n",
    "# https://www.uber.com/blog/h3/\n",
    "# https://spatialthoughts.com/2020/07/01/point-in-polygon-h3-geopandas/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396dde34",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "from h3 import h3\n",
    "import contextily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e558956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the H3 resolution\n",
    "h3_resolution = 8\n",
    " \n",
    "# Creating a function to add the H3 identifier to each of the Airbnb Points\n",
    "def add_h3_id(row):\n",
    "    return h3.geo_to_h3(\n",
    "      row.geometry.y, row.geometry.x, h3_level)\n",
    "\n",
    "# Executing the function\n",
    "listings_manhattan['h3'] = listings_gpdf.apply(add_h3_id, axis=1)\n",
    "\n",
    "# Display the dataframe\n",
    "listings_manhattan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd4a7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe with the count of airbnb's within each hexagon\n",
    "airbnb_count = listings_manhattan.groupby(['h3']).h3.agg('count').to_frame('count').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c581bb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to get the geometry for each of the H3 hexagons\n",
    "def add_h3_geometry(row):\n",
    "    points = h3.h3_to_geo_boundary(\n",
    "      row['h3'], True)\n",
    "    return Polygon(points)\n",
    "\n",
    "# Adding the geometry to the airbnb_count dataframe\n",
    "airbnb_count['geometry'] = airbnb_count.apply(add_geometry, axis=1)\n",
    "\n",
    "# Converting to a geodataframe\n",
    "gdf = gpd.GeoDataFrame(counts, crs='EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0edc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a choropleth map of the Airbnb's within each cell\n",
    "f, ax = plt.subplots(1, figsize=(10, 20))\n",
    "   \n",
    "# Plot choropleth of counts\n",
    "gdf.plot(\n",
    "    column='count', \n",
    "    cmap='coolwarm', \n",
    "    scheme='quantiles',\n",
    "    k=4, \n",
    "    edgecolor='white', \n",
    "    linewidth=0.1, \n",
    "    alpha=0.5,\n",
    "    legend=True,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# Add basemap\n",
    "contextily.add_basemap(\n",
    "    ax,\n",
    "    crs=gdf.crs,\n",
    "    source=contextily.providers.Stamen.TonerLite,\n",
    ")\n",
    "    \n",
    "# Remove axis\n",
    "ax.set_axis_off()\n",
    "\n",
    "# Display\n",
    "plt.show()\n",
    "#f.savefig(path + r\"Neighborhood Residuals.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d606fe3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
