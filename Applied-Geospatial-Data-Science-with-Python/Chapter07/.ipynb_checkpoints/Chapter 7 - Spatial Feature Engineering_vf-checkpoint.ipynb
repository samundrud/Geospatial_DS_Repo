{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2abf8351",
   "metadata": {},
   "source": [
    "## 1. Importing the requisite packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89398e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import geoplot as gplt\n",
    "import contextily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e27cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the data path\n",
    "data_path = r'YOUR FILE PATH'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6210c6e8",
   "metadata": {},
   "source": [
    "## 2. Creating Summary Spatial Features - One Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0eab45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the data from the path\n",
    "locs_pdf = pd.read_csv(data_path + 'OSM_DollarGeneralLocs.csv')\n",
    "\n",
    "# Converting the pandas dataframe into a geopandas geodataframe\n",
    "locs_gdf = gpd.GeoDataFrame(\n",
    "    locs_pdf, geometry=gpd.points_from_xy(locs_pdf.X, locs_pdf.Y),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# Resetting the index and creating a synthetic ID field\n",
    "locs_gdf.reset_index(inplace=True)\n",
    "locs_gdf.rename(columns={'index':'ID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcd542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create a buffer, we first need to convert from a g-crs to a p-crs\n",
    "locs_gdf = locs_gdf.to_crs(3005)\n",
    "\n",
    "# Next, create aggregation area around each store\n",
    "buffer_size_mi = 5\n",
    "buffer_size_m = buffer_size_mi * 1609.344 # meters in a mile\n",
    "\n",
    "# Creating a copy of the original dataframe to operate on\n",
    "locs_gdf_buffer = locs_gdf.copy()\n",
    "\n",
    "# Performing the buffer operation\n",
    "locs_gdf_buffer[\"buffer_5mi\"] = locs_gdf.buffer(buffer_size_m)\n",
    "\n",
    "locs_gdf_buffer[['ID','geometry','X','Y','buffer_5mi']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3195d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining the buffer to the store locations table\n",
    "joined = gpd.sjoin(\n",
    "    \n",
    "    # Right table is the raw store locations data\n",
    "    locs_gdf,\n",
    "    # Left table is that of the buffers around the stores\n",
    "    locs_gdf_buffer.set_geometry(\"buffer_5mi\")[[\"ID\", \"buffer_5mi\"]],\n",
    "    # The operation, or spatial predicate, you'll use is `within`\n",
    "    predicate=\"within\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747934f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store count\n",
    "store_count = (\n",
    "    joined.groupby(\n",
    "        \"ID_left\"\n",
    "    )\n",
    "    .count()\n",
    ")\n",
    "\n",
    "# Converting to a dataframe and cleaning up\n",
    "store_count_df = store_count.reset_index()\n",
    "store_count_df = store_count_df[['ID_left','ID_right']]\n",
    "store_count_df.columns=['ID','Store_Count']\n",
    "\n",
    "store_count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dcae47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing CRS to make mapping cleaner\n",
    "locs_gdf_buffer = locs_gdf_buffer.set_geometry(\"buffer_5mi\")[[\"ID\", \"buffer_5mi\"]]\n",
    "locs_gdf_buffer = locs_gdf_buffer.to_crs(4326)\n",
    "locs_gdf = locs_gdf.to_crs(4326)\n",
    "\n",
    "# Set up figure and axis\n",
    "f, ax = plt.subplots(1, figsize=(12, 12))\n",
    "\n",
    "# Plot Buffer around Store ID 45 in green\n",
    "locs_gdf_buffer[locs_gdf_buffer['ID']==45].plot(ax=ax,color=\"g\")\n",
    "\n",
    "# Plot all stores in red\n",
    "locs_gdf.plot(ax=ax, color=\"r\")\n",
    "\n",
    "# Plot store ID 2 in blue\n",
    "locs_gdf[locs_gdf['ID']==45].plot(ax=ax,color=\"b\")\n",
    "\n",
    "# Add Stamen's Toner basemap\n",
    "contextily.add_basemap(\n",
    "    ax,\n",
    "    crs=locs_gdf.crs.to_string(),\n",
    "    source=contextily.providers.Stamen.Toner,\n",
    ")\n",
    "# Remove axes\n",
    "ax.set_axis_off()\n",
    "# Display\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b44cd78",
   "metadata": {},
   "source": [
    "## 3. Creating Summary Spatial Features - Two Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66470f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the file\n",
    "c_pdf = pd.read_csv(data_path + 'OSM_FamilyDollarLocs.csv')\n",
    "# Converting the pandas dataframe into a geopandas geodataframe\n",
    "c_gdf = gpd.GeoDataFrame(\n",
    "    c_pdf, geometry=gpd.points_from_xy(c_pdf.X, c_pdf.Y), crs = \"EPSG:4326\"\n",
    ")\n",
    "# Converting to a p-CRS\n",
    "c_gdf = c_gdf.to_crs(3005)\n",
    "# Dropping records without valid geometries\n",
    "c_gdf = c_gdf[~(c_gdf['geometry'].is_empty | c_gdf['geometry'].isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07331bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reseting the index and creating a synthetic ID field\n",
    "c_gdf.reset_index(inplace=True)\n",
    "c_gdf.rename(columns={'index':'ID'}, inplace=True)\n",
    "# Cleaning up the data to just being those stores in Ohio\n",
    "Ohio = gpd.read_file(\"https://www2.census.gov/geo/tiger/TIGER2021/STATE/tl_2021_us_state.zip\")\n",
    "Ohio = Ohio[Ohio['STUSPS']==\"OH\"]\n",
    "Ohio = Ohio.to_crs(3005)\n",
    "c_gdf = gpd.overlay(c_gdf, Ohio, how='intersection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bca1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing to a p-crs for the buffer file\n",
    "locs_gdf_buffer = locs_gdf_buffer.to_crs(3005)\n",
    "# Joining the buffer to the store locations table\n",
    "joined = gpd.sjoin(   \n",
    "    # Right table is the competitor stores\n",
    "    c_gdf,\n",
    "    # Left table is that of the buffers around the primary company's Stores\n",
    "    locs_gdf_buffer.set_geometry(\"buffer_5mi\")[[\"ID\", \"buffer_5mi\"]],\n",
    "    # The operation, or spatial predicate, you'll use is `within`\n",
    "    predicate=\"within\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a66bb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store count\n",
    "store_count = (\n",
    "    joined.groupby(\n",
    "        \"ID_left\"\n",
    "    )\n",
    "    .count()\n",
    ")\n",
    "# Converting to a dataframe and cleaning up\n",
    "store_count_df = store_count.reset_index()\n",
    "store_count_df = store_count_df[['ID_left','ID_right']]\n",
    "store_count_df.columns=['ID','Comp_Store_Count']\n",
    "# Displaying the data\n",
    "store_count_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b55f40",
   "metadata": {},
   "source": [
    "## 4. Creating Proximity Spatial Features - NY Airbnb Dataset\n",
    "We'll now turn our attention back to the NYC Airbnb Dataset to calculate proximity spatial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a17d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the data\n",
    "# REMINDER - The listings data must be downloaded from Inside Airbnb\n",
    "listings = pd.read_csv(data_path + r'NY Airbnb June 2020\\listings.csv.gz', compression='gzip', low_memory=False)\n",
    "\n",
    "# Converting it to a GeoPandas DataFrame\n",
    "listings_gpdf = gpd.GeoDataFrame(\n",
    "    listings,\n",
    "    geometry=gpd.points_from_xy(listings['longitude'],\n",
    "                                   listings['latitude'],\n",
    "                                   crs=\"EPSG:4326\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec9b2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focusing on attractions in Manhattan, so we need to create a mask to filter locations \n",
    "# in the Manhattan borough\n",
    "boroughs = gpd.read_file(data_path + r\"NYC Boroughs\\nybb_22a\\nybb.shp\")\n",
    "manhattan = boroughs[boroughs['BoroName']=='Manhattan']\n",
    "manhattan = manhattan.to_crs('EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bf2158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a mask\n",
    "listings_mask = listings_gpdf.within(manhattan.loc[3, 'geometry'])\n",
    "# Using the mask to filter the data\n",
    "listings_manhattan = listings_gpdf.loc[listings_mask]\n",
    "listings_manhattan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee581915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up figure and axis\n",
    "f, ax = plt.subplots(1, figsize=(10, 10))\n",
    "\n",
    "# Plot all airbnb locations in green\n",
    "listings_manhattan.plot(ax=ax, color=\"g\")\n",
    "\n",
    "# Add Stamen's Toner basemap\n",
    "contextily.add_basemap(\n",
    "    ax,\n",
    "    crs=listings_manhattan.crs.to_string(),\n",
    "    source=contextily.providers.Stamen.Watercolor\n",
    ")\n",
    "\n",
    "# Remove axes\n",
    "ax.set_axis_off()\n",
    "\n",
    "# Display\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a383661a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in data on popular NYC Attractions\n",
    "nyc_attr = pd.read_csv(data_path + 'NYC Attractions\\\\NYC Attractions.csv')\n",
    "# Convert PDF to GPDF\n",
    "nyc_attr_gpdf =  gpd.GeoDataFrame(\n",
    "    nyc_attr,\n",
    "    geometry=gpd.points_from_xy(nyc_attr['Longitude'],\n",
    "                                   nyc_attr['Latitude'],\n",
    "                                   crs=\"EPSG:4326\")\n",
    ")\n",
    "# Displaying the top 5 rows of the table\n",
    "nyc_attr_gpdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3b338e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up figure and axis\n",
    "f, ax = plt.subplots(1, figsize=(10, 10))\n",
    "# Plot all attractions in blue\n",
    "nyc_attr_gpdf.plot(ax=ax, color=\"b\")\n",
    "# Add Stamen's Toner basemap\n",
    "contextily.add_basemap(\n",
    "    ax,\n",
    "    crs=nyc_attr_gpdf.crs.to_string(),\n",
    "    source=contextily.providers.Stamen.Watercolor\n",
    ")\n",
    "# Remove axes\n",
    "ax.set_axis_off()\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5471378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "# Set up figure and axis\n",
    "f, ax = plt.subplots(1, figsize=(10, 10))\n",
    "# Plot all airbnb locations in green\n",
    "listings_manhattan.plot(ax=ax, color=\"g\")\n",
    "# Plot all attractions in blue\n",
    "nyc_attr_gpdf.plot(ax=ax, color=\"b\")\n",
    "# Add Stamen's Toner basemap\n",
    "contextily.add_basemap(\n",
    "    ax,\n",
    "    crs=nyc_attr_gpdf.crs.to_string(),\n",
    "    source=contextily.providers.Stamen.Watercolor\n",
    ")\n",
    "\n",
    "# Remove axes\n",
    "ax.set_axis_off()\n",
    "# Manually creating a legend to orient audience\n",
    "green_circle = Line2D([0], [0], marker='o', color='w', label='Airbnbs',\n",
    "                        markerfacecolor='g', markersize=8)\n",
    "blue_circle = Line2D([0], [0], marker='o', color='w', label='Attractions',\n",
    "                        markerfacecolor='b', markersize=8)\n",
    "plt.legend(handles=[green_circle, blue_circle])\n",
    "# Display\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9bc959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the distance to each attraction per airbnb\n",
    "attractions = nyc_attr_gpdf.Attraction.unique()\n",
    "# Converting to a projected coordinate system\n",
    "nyc_attr_gpdf_p = nyc_attr_gpdf.to_crs('EPSG:2263')\n",
    "listings_manhattan_p = listings_manhattan.to_crs('EPSG:2263')\n",
    "# Applying a lambda function that calls geopandas distance function to calcuate the distance between each airbnb and each attraction\n",
    "distances = listings_manhattan_p.geometry.apply(lambda g: nyc_attr_gpdf_p.distance(g)).head()\n",
    "# Renaming the columns based on the attraction for which the distance is calculated\n",
    "distances.columns = attractions\n",
    "# Displaying the top 5 rows of the dataframe\n",
    "distances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a95c082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To understand what the distance unit is, we run the following function\n",
    "listings_manhattan_p.crs.axis_info[0].unit_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc6b4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from 'US survey foot' to miles\n",
    "distances = distances.apply(lambda x: x/5280, axis=1)\n",
    "distances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4745b92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see which locations are less than 2 miles\n",
    "\n",
    "distances_1mi = distances.apply(lambda x: x <=1, axis=1).sum(axis=1)\n",
    "distances_2mi = distances.apply(lambda x: x <=2, axis=1).sum(axis=1)\n",
    "distances_3mi = distances.apply(lambda x: x <=3, axis=1).sum(axis=1)\n",
    "distances_4mi = distances.apply(lambda x: x <=4, axis=1).sum(axis=1)\n",
    "distances_5mi = distances.apply(lambda x: x <=5, axis=1).sum(axis=1)\n",
    "distances_6mi = distances.apply(lambda x: x <=6, axis=1).sum(axis=1)\n",
    "\n",
    "# Creating a dataframe combining all the distance bands\n",
    "distance_df = pd.concat([distances_1mi,distances_2mi,distances_3mi,distances_4mi,distances_5mi,distances_6mi], axis=1)\n",
    "distance_df.columns = ['Attr_1mi','Attr_2mi','Attr_3mi','Attr_4mi','Attr_5mi','Attr_6mi']\n",
    "distance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39384b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining back to the listings geopandas df\n",
    "listings_manhattan = listings_manhattan.merge(distances, left_index=True, right_index=True)\n",
    "listings_manhattan = listings_manhattan.merge(distance_df, left_index=True, right_index=True)\n",
    "\n",
    "#listings_manhattan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a9c948",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_manhattan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de26edd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011b05c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
